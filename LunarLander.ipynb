{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3204d84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0d7b43",
   "metadata": {},
   "source": [
    "1. Always define the environment in the same cell as where it is rendered. Due to the way pygame works, once the environment is closed, you need to remake it. \n",
    "\n",
    "2. The environment below is the base environment. It shows what happens when there is not trained model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dc8816",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"LunarLander-v3\", continuous=False, gravity=-10.0,\n",
    "               enable_wind=False, wind_power=15.0, turbulence_power=1.5, render_mode='human')\n",
    "\n",
    "observation, info = env.reset()\n",
    "for _ in range(1000):\n",
    "    action = env.action_space.sample()\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "    if terminated or truncated:\n",
    "        observation, info = env.reset()\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a7723e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO\n",
    "from gymnasium import Wrapper\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b2cf65",
   "metadata": {},
   "source": [
    "We create this wrapper so that during training our model knows that landing between the flagpoles will result in a bigger reward and that landing close to it is desirable over landing further way from it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef1ebf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrecisionLandingWrapper(Wrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        \n",
    "    def step(self, action):\n",
    "        obs, reward, terminated, truncated, info = self.env.step(action)\n",
    "        \n",
    "        # If the lander has landed (terminated), check landing precision\n",
    "        if terminated:\n",
    "            x_pos = obs[0]  # Horizontal position\n",
    "            \n",
    "            # Landing pad is roughly between x = -0.1 and x = 0.1\n",
    "            # Give bonus reward for landing closer to center\n",
    "            if abs(x_pos) < 0.05:  # Very close to center\n",
    "                reward += 100  # Big bonus\n",
    "            elif abs(x_pos) < 0.1:  # Within landing pad\n",
    "                reward += 50   # Medium bonus\n",
    "            elif abs(x_pos) < 0.2:  # Close to landing pad\n",
    "                reward += 5   # Small bonus\n",
    "            else:  # Far from landing pad\n",
    "                reward -= 50   # Penalty for landing far away\n",
    "                \n",
    "        return obs, reward, terminated, truncated, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2eaabc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_env = PrecisionLandingWrapper(gym.make(\"LunarLander-v3\", continuous=False, gravity=-10.0,\n",
    "                     enable_wind=False, wind_power=15.0, turbulence_power=1.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5af295b",
   "metadata": {},
   "source": [
    "You can change timesteps to whatever you want as timesteps is basically the training time here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee81efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO(\"MlpPolicy\", train_env, verbose=1)\n",
    "model.learn(total_timesteps=200000, log_interval=50)\n",
    "model.save(\"ppo_lunar_lander\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976c946e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load(\"ppo_lunar_lander\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a5347c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_env = gym.make(\"LunarLander-v3\", continuous=False, gravity=-10.0,\n",
    "                     enable_wind=False, wind_power=15.0, turbulence_power=1.5, render_mode='human')\n",
    "\n",
    "obs, info = test_env.reset()\n",
    "for _ in range(5000):\n",
    "    action, _states = model.predict(obs, deterministic=True)\n",
    "    obs, reward, terminated, truncated, info = test_env.step(action)\n",
    "    if terminated or truncated:\n",
    "        obs, info = test_env.reset()\n",
    "test_env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gymenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
